comment = "Write some meaningful comments that can be used in future to identify the intents of running this experiment."

# grammar file
grammar_file = "grammar/grammar"

[train]
model_path = tree_chamfer_full_grammar_cad_{}

# Whether to load a pretrained model or not
preload_model = False

# path to the pre-trained model
pretrain_model_path = "///"

# number of GPU
num_gpu = 1

# Number of epochs to run during training
num_epochs = 5000

# batch size
batch_size = 3

# number of realistic batches in GPU,
# equal to batch size above when the gpu can handle the batch size
gpu_batch = 3

# hidden size of RNN
hidden_size = 1024

# Output feature size from CNN
input_size = 2048

# Canvas shape, keep it 64
canvas_shape = 64

# temeprature decay
temperature = 1

# Learning rate
lr = 0.01

# Entropy coefficient
ec = 0.009

# Optimizer: RL training: "sgd" or supervised training: "adam"
optim = sgd

# l2 Weight decay
weight_decay = 0.0

# dropout for Decoder network
dropout = 0.2

# Encoder dropout
encoder_drop = 0.2

# Whether to schedule the learning rate or not
lr_sch = False

# Number of epochs to wait before decaying the learning rate.
patience = 10

# 1: test, 2: train
mode = 2

# Number of beams
beam_n = 601

# Max length, or max number of shapes
max_len = 6

# program length
program_len = 11

# program data file used for synthetic training
data_file = "///"

# training set size
training_size = 10000

# testing set size
testing_size = 3000

# number of input channels for the encoder
input_channel = 3

# type of reward functions
reward = "chamfer"

# synthetic data or cad data
data_type = "cad"